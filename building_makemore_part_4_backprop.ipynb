{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e241deef",
   "metadata": {},
   "source": [
    "# Continuation of Makemore - MLP - Back prop manually\n",
    "The last tutorial was based on the following paper by [Bengio, et all](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf) and the lovely YouTube series by Andrej Karpathy. This goes forward with more on the MLP thinking through batch normalization and optimiazaion. \n",
    "\n",
    "In the last we made a bigram model through counts and a simple 1 layer NN. This time we will be following this paper to make a version of an MLP. \n",
    "\n",
    "I will be building out a similar to [this tool](https://github.com/karpathy/makemore/tree/master) from scratch. Note that I will be following the tutorial doing it step by step not looking at the final repo. \n",
    "\n",
    "Over all I will work through these papers:\n",
    "- Bigram (one character predicts the next one with a lookup table of counts)\n",
    "- MLP, following [Bengio et al. 2003](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n",
    "- CNN, following [DeepMind WaveNet 2016](https://arxiv.org/abs/1609.03499) (in progress...)\n",
    "- RNN, following [Mikolov et al. 2010](https://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf)\n",
    "- LSTM, following [Graves et al. 2014](https://arxiv.org/abs/1308.0850)\n",
    "- GRU, following [Kyunghyun Cho et al. 2014](https://arxiv.org/abs/1409.1259)\n",
    "- Transformer, following [Vaswani et al. 2017](https://arxiv.org/abs/1706.03762"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e01fa8",
   "metadata": {},
   "source": [
    "Note that right now we don't write backward passes by hand :) It's still good to know though to be able to understand how to debug and avoid problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "258769bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "373cc3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 32033\n",
      "Smallest Word is 2 char while the largest is 15 char\n"
     ]
    }
   ],
   "source": [
    "words = open(\"data/names.txt\", \"r\").read().splitlines()\n",
    "print(f'Total number of words: {len(words)}')\n",
    "smallest = min(len(w) for w in words)\n",
    "largest = max(len(w) for w in words)\n",
    "print(f'Smallest Word is {smallest} char while the largest is {largest} char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf2e15a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the covabulary of chars and mappings \n",
    "chars = sorted(list(set(''.join(words))))\n",
    "str_to_ind = {s:i + 1 for i,s in enumerate(chars)}\n",
    "str_to_ind['.'] = 0\n",
    "ind_to_str = {i:s for s,i in str_to_ind.items()}\n",
    "print(ind_to_str)\n",
    "vocab_size = len(ind_to_str)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bfee539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182580, 3]) torch.Size([182580])\n",
      "torch.Size([22767, 3]) torch.Size([22767])\n",
      "torch.Size([22799, 3]) torch.Size([22799])\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(words, block_size=3):\n",
    "    X, Y = [], []\n",
    "    for word in words:\n",
    "        context = [0] * block_size # padded\n",
    "        for ch in word + '.':\n",
    "            ind = str_to_ind[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ind)\n",
    "            context = context[1:] + [ind] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "block_size=3\n",
    "X_train, Y_train = build_dataset(words[:n1], block_size=block_size)\n",
    "X_dev, Y_dev = build_dataset(words[n1:n2], block_size=block_size)\n",
    "X_test, Y_test = build_dataset(words[n2:], block_size=block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25583bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "    exact = torch.all(dt == t.grad).item()\n",
    "    approx = torch.allclose(dt, t.grad)\n",
    "    max_diff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(exact):5s} | approximate: {str(approx):5s} | max diff: {max_diff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "217c5d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12097\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 0\n",
    "lossi = []\n",
    "n_emb_dim = 10\n",
    "hidden_nodes = 200\n",
    "input_size = n_emb_dim*block_size\n",
    "gain = 5/3 \n",
    "kaining_normal = gain / input_size**0.5\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # reproducibility \n",
    "C = torch.randn((vocab_size, n_emb_dim), generator=g)\n",
    "\n",
    "# Layer 1 \n",
    "W1 = torch.randn((input_size, hidden_nodes),   generator=g) * kaining_normal    \n",
    "b1 = torch.randn(hidden_nodes,                 generator=g) * 0.1 # scale this down to match \n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((hidden_nodes,vocab_size),    generator=g) * 0.1 # useless but in for fun for this lecture\n",
    "b2 = torch.randn(vocab_size,                   generator=g) * 0.1 # zero this out\n",
    "\n",
    "# Batch norm\n",
    "bngain = torch.ones((1, hidden_nodes)) * 0.1 + 1.0\n",
    "bnbias = torch.zeros((1, hidden_nodes)) * 0.1\n",
    "\n",
    "# Note: these are non standard init to make it more obvious \n",
    "# that the backpass was has any errors\n",
    "\n",
    "parameters = [C, W1, W2, b2, bngain, bnbias]\n",
    "\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "401777dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epsilon = 1e-5\n",
    "n = batch_size # convience short name\n",
    "\n",
    "# mini batch\n",
    "ix = torch.randint(0, X_train.shape[0], (batch_size, ), generator=g)\n",
    "Xb, Yb = X_train[ix], Y_train[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81b4e5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6560, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FORWARD PASS\n",
    "# Note this is similar to before, but it has explicit instead of bass cross_entropy\n",
    "# also it's brocken up more to create the back pross\n",
    "\n",
    "emb = C[Xb]     \n",
    "emb_concat = emb.view(emb.shape[0],-1)\n",
    "\n",
    "# Linear layer 1 \n",
    "hidden_pre_bn = emb_concat @W1 + b1\n",
    "\n",
    "# Batch Norm\n",
    "bn_mean_i = 1/n*hidden_pre_bn.sum(0, keepdim=True)\n",
    "bn_diff = hidden_pre_bn - bn_mean_i\n",
    "bn_diff_squared = bn_diff**2\n",
    "bn_var = 1/(n-1) * bn_diff_squared.sum(0, keepdim=True) # note Bessesl's correction (divide by n-1)\n",
    "bn_var_inv = (bn_var + epsilon)**-0.5\n",
    "bn_raw = bn_diff * bn_var_inv\n",
    "hidden_pre_act = bngain *bn_raw + bnbias\n",
    "\n",
    "# non-linearity\n",
    "hidden = torch.tanh(hidden_pre_act)\n",
    "\n",
    "# Linear layer 2\n",
    "logits = hidden @ W2 + b2\n",
    "\n",
    "# cross entropy loss\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = \n",
    "counts_sum_inv = counts_sum**-1 # this is to do bit exact\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "for t in [logprobs, probs, counts_sum_inv, counts_sum, counts,\n",
    "          norm_logits, logit_maxes, logits, hidden, hidden_pre_act,\n",
    "          bn_raw, bn_var_inv, bn_var, bn_diff_squared, bn_diff,\n",
    "          bn_mean_i, hidden_pre_bn,emb_concat, emb\n",
    "         ]:\n",
    "    t.retain_grad()\n",
    "\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9973098b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | max diff: 0.0\n",
      "probs           | exact: True  | approximate: True  | max diff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | max diff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | max diff: 0.0\n",
      "counts          | exact: True  | approximate: True  | max diff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | max diff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | max diff: 0.0\n",
      "logits          | exact: True  | approximate: True  | max diff: 0.0\n",
      "hidden          | exact: True  | approximate: True  | max diff: 0.0\n",
      "W2              | exact: True  | approximate: True  | max diff: 0.0\n",
      "b2              | exact: True  | approximate: True  | max diff: 0.0\n",
      "hidden_pre_act  | exact: True  | approximate: True  | max diff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | max diff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | max diff: 0.0\n",
      "bn_raw          | exact: True  | approximate: True  | max diff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | max diff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | max diff: 0.0\n",
      "bn_diff_squared | exact: True  | approximate: True  | max diff: 0.0\n",
      "bn_diff         | exact: True  | approximate: True  | max diff: 0.0\n",
      "bn_mean_i       | exact: True  | approximate: True  | max diff: 0.0\n",
      "hidden_pre_bn   | exact: True  | approximate: True  | max diff: 0.0\n",
      "emb_concat      | exact: True  | approximate: True  | max diff: 0.0\n",
      "W1              | exact: True  | approximate: True  | max diff: 0.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out)\n * (Tensor input, tuple of ints dim, bool keepdim, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, Tensor out)\n * (Tensor input, name dim, bool keepdim, *, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m cmp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memb_concat\u001b[39m\u001b[38;5;124m'\u001b[39m, dembcat, emb_concat)\n\u001b[1;32m     69\u001b[0m cmp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m'\u001b[39m, dW1, W1)\n\u001b[0;32m---> 70\u001b[0m \u001b[43mcmp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# note: this was done the same way but is failing\u001b[39;00m\n\u001b[1;32m     71\u001b[0m cmp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memb\u001b[39m\u001b[38;5;124m'\u001b[39m, demb, emb)\n\u001b[1;32m     72\u001b[0m cmp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, dC, C)\n",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m, in \u001b[0;36mcmp\u001b[0;34m(s, dt, t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcmp\u001b[39m(s, dt, t):\n\u001b[0;32m----> 2\u001b[0m     exact \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m      3\u001b[0m     approx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mallclose(dt, t\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[1;32m      4\u001b[0m     max_diff \u001b[38;5;241m=\u001b[39m (dt \u001b[38;5;241m-\u001b[39m t\u001b[38;5;241m.\u001b[39mgrad)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mTypeError\u001b[0m: all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out)\n * (Tensor input, tuple of ints dim, bool keepdim, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, Tensor out)\n * (Tensor input, name dim, bool keepdim, *, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1/n # only the one that are in the loss\n",
    "dprobs = 1.0 / probs * dlogprobs\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts_sum = -counts_sum**-2 * dcounts_sum_inv\n",
    "\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum \n",
    "dnorm_logits =  counts * dcounts # counts == e^x\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dlogits).sum(1, keepdim=True)\n",
    "\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T \n",
    "dW2 = hidden.T @ dlogits \n",
    "db2 = dlogits.sum(0, keepdim=True) \n",
    "\n",
    "dhpreact = (1.0 - hidden**2) * dh\n",
    "dbngain = (bn_raw * dhpreact).sum(0, keepdim=True) \n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnvar_inv = (bn_diff * dbnraw).sum(0, keepdim=True)\n",
    "dbndiff = bn_var_inv * dbnraw\n",
    "\n",
    "dbnvar = -0.5 * (bn_var + epsilon)**-1.5 * dbnvar_inv\n",
    "dbndiff2 = (1/(n-1)*torch.ones_like(bn_diff_squared)) * dbnvar\n",
    "dbndiff += 2 * bn_diff * dbndiff2\n",
    "dbnmeani = (-dbndiff).sum(0) \n",
    "dhprebn = dbndiff.clone()+ 1.0/n * (torch.ones_like(hidden_pre_act) * dbnmeani)\n",
    "\n",
    " # hidden_pre_bn = emb_concat @W1 + b1\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = emb_concat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C) \n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k, j]\n",
    "        dC[ix] += demb[k, j] \n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('hidden', dh, hidden)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hidden_pre_act', dhpreact, hidden_pre_act)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bn_raw', dbnraw, bn_raw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bn_var_inv)\n",
    "cmp('bnvar', dbnvar, bn_var)\n",
    "cmp('bn_diff_squared', dbndiff2, bn_diff_squared)\n",
    "cmp('bn_diff', dbndiff, bn_diff)\n",
    "cmp('bn_mean_i', dbnmeani, bn_mean_i)\n",
    "cmp('hidden_pre_bn', dhprebn, hidden_pre_bn)\n",
    "cmp('emb_concat', dembcat, emb_concat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1) # note: this was done the same way but is failing\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "da2f1ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.655993938446045 diff: -2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0c042746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | max diff: 7.916241884231567e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "68c5f5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0194,  0.0071,  0.0038,  0.0204,  0.1258, -0.9365,  0.0402,  0.0110,\n",
       "         0.0333,  0.0056,  0.0066,  0.0051,  0.0188,  0.0876,  0.0055,  0.0028,\n",
       "         0.0441,  0.0144,  0.0097,  0.0667,  0.0450,  0.0020,  0.2198,  0.1213,\n",
       "         0.0069,  0.0123,  0.0013], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "49ca01d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12adcf850>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dlogits are a force to pull down the probs of incorrect and pull up on the correct index\n",
    "# the sum is zero though so it's equal.\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cc388481",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hprebn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Exercise 4 - doing the same for back norm\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# now:\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m hpreact_fast \u001b[38;5;241m=\u001b[39m bngain \u001b[38;5;241m*\u001b[39m (\u001b[43mhprebn\u001b[49m \u001b[38;5;241m-\u001b[39m hprebn\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(hprebn\u001b[38;5;241m.\u001b[39mvar(\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, unbiased\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-5\u001b[39m) \u001b[38;5;241m+\u001b[39m bnbias\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax diff:\u001b[39m\u001b[38;5;124m'\u001b[39m, (hpreact_fast \u001b[38;5;241m-\u001b[39m hpreact)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hprebn' is not defined"
     ]
    }
   ],
   "source": [
    "# Exercise 4 - doing the same for back norm\n",
    "\n",
    "# forward pass\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f161c593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38398724",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 200000\n",
    "learning_rate = 0.1\n",
    "decay = 0.1\n",
    "batch_size = 32\n",
    "decay_threshold = 100000\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    # minibatch contstruct, faster although not exact\n",
    "\n",
    "    \n",
    "    # forward\n",
    "    emb = C[Xb]     \n",
    "    emb_concat = emb.view(emb.shape[0],-1)\n",
    "    hidden_pr e_activation = emb_concat @ W1\n",
    "    \n",
    "    # batch normlaizaiton\n",
    "    hidden_mean = hidden_pre_activation.mean(0, keepdim=True)\n",
    "    hidden_std = hidden_pre_activation.std(0, keepdim=True)\n",
    "    hidden_pre_activation = bngain * (hidden_pre_activation - hidden_mean) / hidden_std + bnbias\n",
    "    \n",
    "    \n",
    "    # calculate the running bmean and bstd, slight smoothing\n",
    "    with torch.no_grad():\n",
    "        bnmean_running = 0.999 * bnmean_running + 0.001 * hidden_mean\n",
    "        bnstd_running = 0.999 * bnstd_running + 0.001 * hidden_std\n",
    "    \n",
    "    hidden = torch.tanh(hidden_pre_activation)      \n",
    "    logits = hidden @ W2 + b2                            \n",
    "    loss = F.cross_entropy(logits, Yb)\n",
    "\n",
    "    # backward\n",
    "    for p in parameters:\n",
    "        p.grad = None # zero_grade\n",
    "        \n",
    "    loss.backward()\n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data += -learning_rate * p.grad\n",
    "    \n",
    "    if total_epochs > 0 and total_epochs%decay_threshold == 0:\n",
    "        learning_rate *= decay\n",
    "        \n",
    "            \n",
    "    if i % 10000 == 0 or i == epoch-1:\n",
    "        print(f\"epoch: {total_epochs:6} batch: {i:7}/{epoch:7} loss: {loss.item():5.3f}\")\n",
    "\n",
    "    # track stats\n",
    "    lossi.append(loss.log10().item())\n",
    "    total_epochs += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_learning",
   "language": "python",
   "name": "ml_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
