{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af96cd5",
   "metadata": {},
   "source": [
    "# Building MakeMore - Moving to CNN\n",
    "\n",
    "Last time we implemented the architecture of WaveNet, but without the residual gates or the convolutions, just the heirachical. This time around we are going to add in the convolutions instead of only the Linear. Andrej Karparthy turtorials stop at the last one so we will be going forward learning it ourselves. \n",
    "\n",
    "\n",
    "Over all I will work through these papers:\n",
    "- Bigram (one character predicts the next one with a lookup table of counts)\n",
    "- MLP, following [Bengio et al. 2003](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n",
    "- CNN, following [DeepMind WaveNet 2016](https://arxiv.org/abs/1609.03499) \n",
    "- RNN, following [Mikolov et al. 2010](https://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf)\n",
    "- LSTM, following [Graves et al. 2014](https://arxiv.org/abs/1308.0850)\n",
    "- GRU, following [Kyunghyun Cho et al. 2014](https://arxiv.org/abs/1409.1259)\n",
    "- Transformer, following [Vaswani et al. 2017](https://arxiv.org/abs/1706.03762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a521edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets import the starter code\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import scipy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e54198",
   "metadata": {},
   "source": [
    "# Let's learn CNN\n",
    "A convolution is a summation of the some product. The math for this for 1d is take two arrays, flip the second one, and then slide it over the with the first doing this summation of product on each. This is shown below. \n",
    "\n",
    "Now when we think of this for images we have the main image (2d with no channels for gray scale) and a filter or kernal that is smaller. This smaller knernal get's slide across the image resulting in a new tensor. This is used for edge detection, guassian blur, etc. In a CNN this kernal is not set to certain values but it is learned. \n",
    "\n",
    "Convolutions are quite intensive O(N^2) but we can use Fast Fourier Transform (since this is a discrete Fourier transform) to get us to O(NlogN) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d24033e",
   "metadata": {},
   "source": [
    "np.convolve((1,2,3), (4,5,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "149c8153",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.random.random(100000)\n",
    "arr2 = np.random.random(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c1cd4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.69 s ± 22.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.convolve(arr1, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca59888f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.96 ms ± 1.17 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "scipy.signal.fftconvolve(arr1, arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df55f0",
   "metadata": {},
   "source": [
    "Notice that the output of this is bigger than the original arrays. This is why there are pooling layers without weights that run across it afterwards to get it back to the original size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c937891f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.0000, 13.0000, 28.0000, 27.0000, 18.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.tensor(scipy.signal.fftconvolve((1,2,3), (4,5,6))).view(1, 5)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e66020db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.0000, 28.0000, 27.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.MaxPool1d(2, padding=1) \n",
    "pooled_output = m(output)\n",
    "pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7898311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_learning",
   "language": "python",
   "name": "ml_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
